from flask import Flask, request, jsonify
import requests
from query_postgresql import query_postgresql
from question import DASS_21 , DASS_choices , summaryScore , save_dass_result
from dotenv import load_dotenv
import os
import google.generativeai as genai
from collections import deque
import threading
import time

# ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏°‡∏≤‡∏ï‡∏¥‡∏î‡πÜ ‡∏Å‡∏±‡∏ô
user_message_buffer = {}
user_timers = {}

load_dotenv()

#env 
LineToken = os.getenv("LINE_ACCESS_TOKEN")
llmEndpoint = os.getenv("LOCAL_LLM_ENDPOINT")
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

app = Flask(__name__)

### ‡πÄ‡∏Å‡πá‡∏ö ID , score , ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
user_states = {}

### ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏™‡∏ô‡∏ó‡∏ô‡∏≤
chat_histories = {}

# ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥
def format_history(history):
    return "\n".join([f"{m['role'].capitalize()}: {m['content']}" for m in history])

def reply_message(reply_token, message):
    headers = {
        "Authorization": f"Bearer {LineToken}",
        "Content-Type": "application/json"
    }
    body = {
        "replyToken": reply_token,
        "messages": [{"type": "text", "text": message}]
    }
    requests.post("https://api.line.me/v2/bot/message/reply", headers=headers, json=body)

def process_combined_messages(user_id, reply_token):
    buffer = user_message_buffer.get(user_id, deque())

    # ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÄ‡∏ß‡∏•‡∏≤
    combined_message = "\n".join([msg for msg, _ in buffer])

    if not combined_message.strip():
        return

    # ‡∏•‡πâ‡∏≤‡∏á buffer ‡∏´‡∏•‡∏±‡∏á‡πÉ‡∏ä‡πâ
    user_message_buffer[user_id] = deque()

    # ‡∏ó‡∏≥‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°‡∏à‡∏≤‡∏Å‡πÇ‡∏Ñ‡πâ‡∏î‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì
    query_text = combined_message
    print(f"Processing combined message: {query_text}")
    retrieved_docs = query_postgresql(query_text)
    context = "\n".join([doc[0] for doc in retrieved_docs]) if retrieved_docs else "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á"

    if user_id not in chat_histories:
        chat_histories[user_id] = []

    history_text = format_history(chat_histories[user_id])

    prompt = (
        "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏≠‡∏ö‡∏≠‡∏∏‡πà‡∏ô‡πÅ‡∏•‡∏∞‡πÄ‡∏Ç‡πâ‡∏≤‡∏≠‡∏Å‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à\n"
        "‡πÄ‡∏ô‡πâ‡∏ô‡∏ï‡∏≠‡∏ö‡∏ï‡∏£‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å\n"
        "‡∏´‡∏≤‡∏Å‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô ‡∏Ñ‡πà‡∏≠‡∏¢‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤ ‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á\n\n"

        f"‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ:\n{query_text}\n\n"
        f"‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° (‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•):\n{context}\n\n"
        f"‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤:\n{history_text or '‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤'}\n\n"

        "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏†‡∏≤‡∏û ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á ‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡∏¢‡∏≤‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ\n"
        "‡∏´‡∏≤‡∏Å‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏°‡πà‡πÅ‡∏ô‡πà‡πÉ‡∏à‡πÉ‡∏ô‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö ‡πÇ‡∏õ‡∏£‡∏î‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡πà‡∏≤‡πÑ‡∏°‡πà‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏∏‡∏†‡∏≤‡∏û"
    )

    model = genai.GenerativeModel("gemma-3-27b-it")  
    response = model.generate_content([{"role": "user", "parts": [prompt]}])
    reply_text = response.text.strip() or "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡∏â‡∏±‡∏ô‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏Ñ‡πà‡∏∞"

    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥
    chat_histories[user_id].append({"role": "user", "content": query_text})
    chat_histories[user_id].append({"role": "assistant", "content": reply_text})
    chat_histories[user_id] = chat_histories[user_id][-6:]

    # ‡∏™‡πà‡∏á‡∏Å‡∏•‡∏±‡∏ö
    reply_message(reply_token, reply_text)

@app.route("/webhook", methods=["POST"])
def webhook():
    data = request.json
    for event in data["events"]:
        if event["type"] == "message" and event["message"]["type"] == "text":
            user_text = event["message"]["text"].strip()
            reply_token = event["replyToken"]
            user_id = event["source"]["userId"]

            if user_text.lower() in ["‡∏ó‡∏≥‡πÅ‡∏ö‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô" , "‡πÅ‡∏ö‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô" , "‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÅ‡∏ö‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô"]:
                user_states[user_id] = {"index": 0, "scores": []}
                q = DASS_21[0]["text"]
                reply_message(reply_token,  f"‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÅ‡∏ö‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô DASS-21\n\n{q}\n\n‡∏ï‡∏≠‡∏ö‡πÇ‡∏î‡∏¢‡∏û‡∏¥‡∏°‡∏û‡πå‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç:\n0 = ‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢\n1 = ‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏≤‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á\n2 = ‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡πà‡∏≠‡∏¢‡∏Ñ‡∏£‡∏±‡πâ‡∏á\n3 = ‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡∏à‡∏≥")
                return jsonify({"status": "ok"})
            
            if user_text.lower() in ["‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å" ,"‡∏≠‡∏≠‡∏Å", "‡πÄ‡∏•‡∏¥‡∏Å‡∏ó‡∏≥‡πÅ‡∏ö‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô "]:
                if user_id in user_states:
                    del user_states[user_id]
                    reply_message(reply_token ,"‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏î‡πâ‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡πÅ‡∏ö‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÅ‡∏•‡πâ‡∏ß ‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÉ‡∏´‡∏°‡πà ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏ß‡πà‡∏≤ '‡∏ó‡∏≥‡πÅ‡∏ö‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô' ‡∏Ñ‡πà‡∏∞ üòä")

            if user_id in user_states:
                state = user_states[user_id]
                index = state["index"]

                if user_text in DASS_choices:
                    score = DASS_choices[user_text]

                    if index < len(DASS_21):  
                        q_type = DASS_21[index]["type"]
                        state["scores"].append({"score": score, "type": q_type})
                        index += 1
                        state["index"] = index

                    if index < len(DASS_21):
                        next_q = DASS_21[index]["text"]
                        reply_message(reply_token, f"{next_q}\n\n‡∏ï‡∏≠‡∏ö‡πÇ‡∏î‡∏¢‡∏û‡∏¥‡∏°‡∏û‡πå‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç:\n0 = ‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢\n1 = ‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏≤‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á\n2 = ‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡πà‡∏≠‡∏¢‡∏Ñ‡∏£‡∏±‡πâ‡∏á\n3 = ‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡∏à‡∏≥")
                    else:
                        summary = summaryScore(state["scores"])
                        d, a, s = summary['D'], summary['A'], summary['S']
                        d_level, a_level, s_level = save_dass_result(user_id, d, a, s)
                        reply_message(reply_token, 
    f"""üéâ ‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏≥‡πÅ‡∏ö‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô DASS-21 ‡∏Ñ‡∏£‡∏ö‡πÅ‡∏•‡πâ‡∏ß!

üìù ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏£‡∏ß‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì:
‚Ä¢ ‡∏ã‡∏∂‡∏°‡πÄ‡∏®‡∏£‡πâ‡∏≤ (Depression): {d} ‚Üí **{d_level}**
‚Ä¢ ‡∏ß‡∏¥‡∏ï‡∏Å‡∏Å‡∏±‡∏á‡∏ß‡∏• (Anxiety): {a} ‚Üí **{a_level}**
‚Ä¢ ‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î (Stress): {s} ‚Üí **{s_level}**

‡∏´‡∏≤‡∏Å‡∏Ñ‡∏∏‡∏ì‡∏≠‡∏¢‡∏≤‡∏Å‡∏û‡∏π‡∏î‡∏Ñ‡∏∏‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°  
‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏ô‡∏∞‡∏Ñ‡∏∞ üòä"""
)

                        del user_states[user_id]
                else:
                    reply_message(reply_token, "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç:\n0 = ‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢\n1 = ‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏≤‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á\n2 = ‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡πà‡∏≠‡∏¢‡∏Ñ‡∏£‡∏±‡πâ‡∏á\n3 = ‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡∏à‡∏≥")
                return jsonify({"status": "ok"})


            query_text = user_text
            retrieved_docs = query_postgresql(query_text)   
            # print(" Retrieved Docs:", retrieved_docs) 

            #‡πÅ‡∏õ‡∏•‡∏á array ‡πÄ‡∏õ‡πá‡∏ô string
            context = "\n".join([doc[0] for doc in retrieved_docs])if retrieved_docs else "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á"

            #‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡∏õ‡∏£‡∏∞‡∏ß‡∏¥‡∏ï‡∏¥‡∏™‡∏ô‡∏ó‡∏ô‡∏≤
            if user_id not in chat_histories:
                chat_histories[user_id] = []

            history_text = format_history(chat_histories[user_id])
            # print("history_Text : "+ history_text)

            prompt = (
                "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏≠‡∏ö‡∏≠‡∏∏‡πà‡∏ô‡πÅ‡∏•‡∏∞‡πÄ‡∏Ç‡πâ‡∏≤‡∏≠‡∏Å‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à\n"
                "‡πÄ‡∏ô‡πâ‡∏ô‡∏ï‡∏≠‡∏ö‡∏ï‡∏£‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å\n"
                "‡∏´‡∏≤‡∏Å‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô ‡∏Ñ‡πà‡∏≠‡∏¢‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤ ‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á\n\n"

                f" ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ:\n{query_text}\n\n"
                
                f" ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° (‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•):\n{context if context else '‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á'}\n\n"
                
                f" ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤:\n{history_text if history_text else '‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤'}\n\n"
                
                "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏†‡∏≤‡∏û ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á ‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡∏¢‡∏≤‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ\n"
                "‡∏´‡∏≤‡∏Å‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏°‡πà‡πÅ‡∏ô‡πà‡πÉ‡∏à‡πÉ‡∏ô‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö ‡πÇ‡∏õ‡∏£‡∏î‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡πà‡∏≤‡πÑ‡∏°‡πà‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏∏‡∏†‡∏≤‡∏û"
            )
            
            llm_payload = {
                "model": "test-finetune-2",
                "messages": [
                    {"role": "system", "content": (
                        "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡∏≠‡∏ö‡∏≠‡∏∏‡πà‡∏ô ‡∏™‡∏∏‡∏†‡∏≤‡∏û ‡πÅ‡∏•‡∏∞‡πÄ‡∏´‡πá‡∏ô‡∏≠‡∏Å‡πÄ‡∏´‡πá‡∏ô‡πÉ‡∏à‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ\n"
                        "‡πÇ‡∏õ‡∏£‡∏î‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢ ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£\n"
                        "‡∏ñ‡πâ‡∏≤‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏Ñ‡∏¢‡∏û‡∏π‡∏î‡∏ñ‡∏∂‡∏á‡∏ä‡∏∑‡πà‡∏≠ ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏à‡∏≥‡πÑ‡∏ß‡πâ‡πÅ‡∏•‡∏∞‡πÉ‡∏™‡πà‡πÉ‡∏à‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö\n"
                        "‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠ ‡πÉ‡∏´‡πâ‡∏ö‡∏≠‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏∏‡∏†‡∏≤‡∏û‡∏ß‡πà‡∏≤‡πÑ‡∏°‡πà‡πÅ‡∏ô‡πà‡πÉ‡∏à ‡πÅ‡∏ó‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≤‡∏î‡πÄ‡∏î‡∏≤"
                    )},
                    {"role": "user", "content": prompt}
                ],
                "max_tokens": 200,
                "temperature": 0.6
            }

            # llm_response = requests.post(llmEndpoint, json=llm_payload).json()
            # reply_text = llm_response.get("choices", [{}])[0].get("message", {}).get("content", "").strip()

            # model = genai.GenerativeModel("gemma-3-27b-it")  
            # response = model.generate_content([
            #     {"role": "user", "parts": [prompt]}
            # ])
            # reply_text = response.text.strip()

            # # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÉ‡∏ô session
            # chat_histories[user_id].append({"role": "user", "content": query_text})
            # chat_histories[user_id].append({"role": "assistant", "content": reply_text})

            # # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 10 ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (5 user  5 assistant)
            # chat_histories[user_id] = chat_histories[user_id][-6:]

            # if not reply_text:
            #     reply_text = "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡∏â‡∏±‡∏ô‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏Ñ‡πà‡∏∞"
            # reply_message(reply_token, reply_text)

            #  ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡πà‡∏≠‡∏ô‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ LLM
            if user_id not in user_message_buffer:
                user_message_buffer[user_id] = deque()
            user_message_buffer[user_id].append((user_text, time.time()))

            # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ timer ‡∏£‡∏≠‡∏≠‡∏¢‡∏π‡πà ‡πÉ‡∏´‡πâ‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å‡∏Å‡πà‡∏≠‡∏ô
            if user_id in user_timers and user_timers[user_id].is_alive():
                user_timers[user_id].cancel()

            # ‡∏ï‡∏±‡πâ‡∏á‡πÄ‡∏ß‡∏•‡∏≤ 3 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ ‡πÅ‡∏•‡πâ‡∏ß‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏™‡πà‡∏á‡πÑ‡∏õ LLM
            user_timers[user_id] = threading.Timer(3.0, process_combined_messages, args=[user_id, reply_token])
            user_timers[user_id].start()

    return jsonify({"status": "ok"})

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)

